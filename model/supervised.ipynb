{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/u/13/italinv1/unix/PycharmProjects/veera-thesis/aparc_data/'\n",
    "BATCH_SIZE = 64\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_SEED = 123\n",
    "AGG = 'max'\n",
    "\n",
    "cases = ['%03d' % n for n in range(28)]\n",
    "\n",
    "freq_bands = [\n",
    "    (1, 4),\n",
    "    (4, 8),\n",
    "    (8, 10),\n",
    "    (10, 13),\n",
    "    (13, 30),\n",
    "    (30, 40)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_csv(filename):\n",
    "    # Helper for creating a matrix out of csv data\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    matrix = df.values\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, normalize=True, decim_freqs=None):\n",
    "    if data.shape[-1] % 2 != 0:\n",
    "        data = np.insert(data, -1, data[:,:,-1], axis=2)\n",
    "        \n",
    "    if decim_freqs and type(decim_freqs) == int:\n",
    "        data = data[:, :, ::decim_freqs]\n",
    "    \n",
    "    elif type(decim_freqs) == str and decim_freqs == 'bands':\n",
    "        binned_data = []\n",
    "        for (lo, hi) in freq_bands:\n",
    "            lo_ind, hi_ind = lo*8, hi*8\n",
    "            binned_data.append(np.max(data[:,:,lo_ind:hi_ind], axis=-1))\n",
    "        data = np.transpose(np.asarray(binned_data), (1, 2, 0))\n",
    "    \n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "    if normalize:\n",
    "        x_scaler = StandardScaler()\n",
    "        data = x_scaler.fit_transform(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data_path=None):\n",
    "    if data_path is None:\n",
    "        return\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for filename in glob(os.path.join(data_path, f\"*{AGG}-aparc-data.csv\")):\n",
    "        data_arr = download_from_csv(filename)\n",
    "        if os.path.basename(filename)[:3] in cases:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        X.append(data_arr)\n",
    "        y.append(label)\n",
    "    X = preprocess(np.asarray(X), decim_freqs='bands', normalize=False)\n",
    "    return X, np.asarray(y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666, 18000) (666,)\n"
     ]
    }
   ],
   "source": [
    "X, y = get_dataset(DATA_DIR)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/13/italinv1/unix/.conda/envs/tbi/lib/python3.8/site-packages/imblearn/utils/_validation.py:318: UserWarning: After over-sampling, the number of samples (6000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 641)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 641, 1: 25})\n",
      "Resampled dataset shape Counter({0: 6000, 1: 25})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=RANDOM_SEED, sampling_strategy={0:6000, 1:25})\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1205, 18000)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1205,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set is 4820 documents (22 positive)\n",
      "Test set is 1205 documents (3 positive)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set is %d documents (%d positive)\" % (len(y_train), sum(y_train)))\n",
    "print(\"Test set is %d documents (%d positive)\" % (len(y_test), sum(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination = sum(y_train) / len(y_train)\n",
    "#clf = SGDClassifier(random_state=RANDOM_SEED, penalty='l1', class_weight={0:5, 1:1})\n",
    "#clf = OneClassSVM(gamma='scale', nu=0.04)\n",
    "clf = IsolationForest(contamination=contamination, n_estimators=100, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.004564315352697096, n_jobs=2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train[y_train==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5332244137809049\n"
     ]
    }
   ],
   "source": [
    "print(clf.offset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = clf.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2 = y_test.copy()\n",
    "y_test2[y_test==0] = 1\n",
    "y_test2[y_test==1] = -1\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818182"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test2, y_hat, pos_label=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, y_pred):\n",
    "\n",
    "    total_anom = sum(y_true == -1)  \n",
    "    tp = sum((y_true == -1) & (y_pred == -1))\n",
    "    fp = sum((y_true != -1) & (y_pred == -1))\n",
    "    tn = sum((y_true != -1) & (y_pred != -1))\n",
    "    fn = sum((y_true == -1) & (y_pred != -1))\n",
    "    \n",
    "    print('[TP] {}\\t\\t[FP] {}\\t\\t[MISSED] {}'.format(tp, fp, total_anom-tp))\n",
    "    print('[TN] {}\\t[FN] {}'.format(tn, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TP] 1\t\t[FP] 7\t\t[MISSED] 2\n",
      "[TN] 1195\t[FN] 2\n"
     ]
    }
   ],
   "source": [
    "print_results(y_test2, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
